{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# This is a sample Jupyter Notebook\n",
    "\n",
    "Below is an example of a code cell. \n",
    "Put your cursor into the cell and press Shift+Enter to execute it and select the next one, or click 'Run Cell' button.\n",
    "\n",
    "Press Double Shift to search everywhere for classes, files, tool windows, actions, and settings.\n",
    "\n",
    "To learn more about Jupyter Notebooks in PyCharm, see [help](https://www.jetbrains.com/help/pycharm/ipython-notebook-support.html).\n",
    "For an overview of PyCharm, go to Help -> Learn IDE features or refer to [our documentation](https://www.jetbrains.com/help/pycharm/getting-started.html)."
   ],
   "id": "8a77807f92f26ee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T08:28:59.350742Z",
     "start_time": "2025-10-30T08:28:57.440299Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('data\\\\shopee_reviews.csv')\n",
    "\n",
    "# Function to modify the label based on the rules\n",
    "def modify_label(value):\n",
    "    # Convert to string and strip whitespace to handle both numeric and string types\n",
    "    str_value = str(value).strip()\n",
    "    if str_value in ['1', '2']:\n",
    "        return 'Neg'\n",
    "    elif str_value == '3':\n",
    "        return 'Neu'\n",
    "    elif str_value in ['4', '5']:\n",
    "        return 'Pos'\n",
    "    else:\n",
    "        return value  # Keep unchanged if it doesn't match\n",
    "\n",
    "# Apply the modification to the 'label' column\n",
    "df['label'] = df['label'].apply(modify_label)\n",
    "\n",
    "# Reduce the number of 'Pos' records to 100,000 by random sampling\n",
    "pos_df = df[df['label'] == 'Pos']\n",
    "if len(pos_df) > 55000:\n",
    "    pos_df = pos_df.sample(n=55000, random_state=42)  # random_state for reproducibility\n",
    "\n",
    "# Keep all other records\n",
    "other_df = df[df['label'] != 'Pos']\n",
    "\n",
    "# Combine the reduced 'Pos' with others\n",
    "modified_df = pd.concat([pos_df, other_df], ignore_index=True)\n",
    "\n",
    "# Optionally, save the modified DataFrame to a new CSV file\n",
    "modified_df.to_csv('modified_shopee_reviews.csv', index=False)\n",
    "\n",
    "# Print a summary\n",
    "print(\"Original shape:\", df.shape)\n",
    "print(\"Modified shape:\", modified_df.shape)\n",
    "print(modified_df['label'].value_counts())"
   ],
   "id": "7fa2ee7317808c1a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_24480\\1244998731.py:4: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('data\\\\shopee_reviews.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (1502575, 2)\n",
      "Modified shape: (151514, 2)\n",
      "label\n",
      "Pos      55000\n",
      "Neu      49083\n",
      "Neg      47430\n",
      "label        1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T08:41:20.283575Z",
     "start_time": "2025-10-30T08:41:19.864370Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import nltk\n",
    "\n",
    "# Tải xuống resource cần thiết\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('punkt')        # Vẫn nên tải để đảm bảo\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ],
   "id": "224694f95b08bca3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T08:43:28.272661Z",
     "start_time": "2025-10-30T08:43:05.237302Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# === TẢI DỮ LIỆU NLTK (chỉ cần chạy 1 lần) ===\n",
    "nltk.download('punkt_tab', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "\n",
    "# === ĐỌC FILE CSV ===\n",
    "df = pd.read_csv('modified_shopee_reviews.csv')\n",
    "\n",
    "# === TÊN CỘT NỘI DUNG ĐÁNH GIÁ ===\n",
    "text_column = 'text'  # ← ĐÃ ĐÚNG: cột tên là 'text'\n",
    "\n",
    "# Kiểm tra cột tồn tại\n",
    "if text_column not in df.columns:\n",
    "    raise KeyError(f\"Cột '{text_column}' không tồn tại. Các cột có: {df.columns.tolist()}\")\n",
    "\n",
    "# === HÀM TIỀN XỬ LÝ VĂN BẢN (TIẾNG ANH) ===\n",
    "def preprocess_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "\n",
    "    # 1. Chuyển thành chữ thường\n",
    "    text = str(text).lower()\n",
    "\n",
    "    # 2. Xóa URL và ký tự đặc biệt (chỉ giữ chữ cái và khoảng trắng)\n",
    "    text = re.sub(r'http[s]?://\\S+|www\\.\\S+', '', text)  # Xóa URL\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)                  # Xóa icon, dấu câu, số\n",
    "\n",
    "    # 3. Tokenize (tách từ)\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # 4. Loại bỏ stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words and len(word) > 1]\n",
    "\n",
    "    # 5. Lemmatization (đưa về dạng gốc)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "    # Ghép lại thành chuỗi\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# === ÁP DỤNG CHO CỘT 'text' → TẠO CỘT MỚI 'clean_review' ===\n",
    "print(f\"Đang xử lý cột: '{text_column}'...\")\n",
    "df['clean_review'] = df[text_column].apply(preprocess_text)\n",
    "\n",
    "# === LƯU FILE MỚI ===\n",
    "output_file = 'preprocessed_shopee_reviews.csv'\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "# === HOÀN TẤT ===\n",
    "print(\"\\nHOÀN TẤT TIỀN XỬ LÝ!\")\n",
    "print(f\"File đã lưu: {output_file}\")\n",
    "print(f\"Tổng số dòng: {len(df):,}\")\n",
    "print(f\"Số dòng Pos: {(df['label'] == 'Pos').sum():,}\")\n",
    "print(\"\\nVí dụ 3 dòng đầu (clean_review):\")\n",
    "print(df[['text', 'clean_review']].head(3).to_string(index=False))"
   ],
   "id": "422f0e19cbfda0b4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang xử lý cột: 'text'...\n",
      "\n",
      "HOÀN TẤT TIỀN XỬ LÝ!\n",
      "File đã lưu: preprocessed_shopee_reviews.csv\n",
      "Tổng số dòng: 151,514\n",
      "Số dòng Pos: 55,000\n",
      "\n",
      "Ví dụ 3 dòng đầu (clean_review):\n",
      "                                                                                                                                                                                                            text                                                                                                                                          clean_review\n",
      "                                                                                                                                                                                                    Awesome ❤️❤️                                                                                                                                               awesome\n",
      "                                                                                          My daughter love it. Fast delivery. D seller is very kind to update on the delivery. Tqsm.. will definitely buy again.                                                                           daughter love fast delivery seller kind update delivery tqsm definitely buy\n",
      "Mothers day gift. Great phone, chose this model after much comparison of the specs. They offer 6gb ram and 128gb storage, very sufficient for usage. Delivery was quick and there's a free gift - glass bottle.  mother day gift great phone chose model much comparison spec offer 6gb ram 128gb storage sufficient usage delivery quick there free gift glass bottle\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T08:55:35.524925Z",
     "start_time": "2025-10-30T08:55:33.635590Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 1. Load dữ liệu\n",
    "# ------------------------------------------------------------------\n",
    "df = pd.read_csv('preprocessed_shopee_reviews.csv')\n",
    "\n",
    "# Kiểm tra cột cần thiết\n",
    "assert 'clean_review' in df.columns, \"Cột 'clean_review' không tồn tại!\"\n",
    "assert 'label' in df.columns, \"Cột 'label' không tồn tại!\"\n",
    "\n",
    "# Loại bỏ các row không hợp lệ (ví dụ: header bị lẫn hoặc giá trị không phải nhãn thực)\n",
    "# Giả sử nhãn hợp lệ chỉ là 'Pos', 'Neg', 'Neu'\n",
    "valid_labels = ['Pos', 'Neg', 'Neu']\n",
    "df = df[df['label'].isin(valid_labels)]\n",
    "\n",
    "# Hoặc cụ thể loại bỏ nếu 'label' == 'label'\n",
    "# df = df[df['label'] != 'label']\n",
    "\n",
    "X = df['clean_review'].astype(str)   # TF-IDF chấp nhận chuỗi\n",
    "y = df['label']\n",
    "\n",
    "print(f\"Tổng số mẫu sau lọc: {len(df)}\")\n",
    "print(\"Phân bố nhãn sau lọc:\")\n",
    "print(y.value_counts())\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2. Xử lý lớp hiếm (có < 2 mẫu) → gộp vào lớp 'Other' nếu cần\n",
    "# ------------------------------------------------------------------\n",
    "min_samples = 2\n",
    "label_counts = Counter(y)\n",
    "\n",
    "rare_labels = [lbl for lbl, cnt in label_counts.items() if cnt < min_samples]\n",
    "if rare_labels:\n",
    "    print(f\"\\nCác nhãn hiếm (< {min_samples} mẫu): {rare_labels}\")\n",
    "    # Thay thế các nhãn hiếm bằng 'Other'\n",
    "    y = y.replace(to_replace=rare_labels, value='Other')\n",
    "    print(\"Đã gộp các nhãn hiếm thành 'Other'.\")\n",
    "else:\n",
    "    print(\"\\nKhông có nhãn hiếm nào cần xử lý.\")\n",
    "\n",
    "print(\"\\nPhân bố nhãn cuối cùng:\")\n",
    "print(pd.Series(y).value_counts())\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 3. Chia train / test\n",
    "# ------------------------------------------------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y          # giữ tỷ lệ nhãn\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain size : {X_train.shape[0]}\")\n",
    "print(f\"Test  size : {X_test.shape[0]}\")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 4. Vector hóa TF-IDF\n",
    "# ------------------------------------------------------------------\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=10_000,   # giới hạn để chạy nhanh, có thể bỏ nếu RAM đủ\n",
    "    sublinear_tf=True,     # thường cho hiệu suất tốt hơn\n",
    "    ngram_range=(1, 1)     # unigram; có thể thử (1,2) nếu muốn\n",
    ")\n",
    "\n",
    "# Chỉ fit trên tập train\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform tập test (không fit lại)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "print(f\"\\nX_train_tfidf shape: {X_train_tfidf.shape}\")\n",
    "print(f\"X_test_tfidf  shape: {X_test_tfidf.shape}\")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 5. (Tuỳ chọn) Lưu vectorizer & dữ liệu đã chia để dùng sau\n",
    "# ------------------------------------------------------------------\n",
    "import joblib\n",
    "joblib.dump(vectorizer, 'tfidf_vectorizer.pkl')\n",
    "joblib.dump((X_train_tfidf, X_test_tfidf, y_train, y_test),\n",
    "            'tfidf_split_data.pkl')\n",
    "\n",
    "print(\"\\nĐÃ HOÀN TẤT! Các biến sẵn sàng:\")\n",
    "print(\"   X_train_tfidf, X_test_tfidf, y_train, y_test\")\n",
    "print(\"   Vectorizer được lưu: tfidf_vectorizer.pkl\")"
   ],
   "id": "78b88624605183",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tổng số mẫu sau lọc: 151513\n",
      "Phân bố nhãn sau lọc:\n",
      "label\n",
      "Pos    55000\n",
      "Neu    49083\n",
      "Neg    47430\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Không có nhãn hiếm nào cần xử lý.\n",
      "\n",
      "Phân bố nhãn cuối cùng:\n",
      "label\n",
      "Pos    55000\n",
      "Neu    49083\n",
      "Neg    47430\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Train size : 121210\n",
      "Test  size : 30303\n",
      "\n",
      "X_train_tfidf shape: (121210, 10000)\n",
      "X_test_tfidf  shape: (30303, 10000)\n",
      "\n",
      "ĐÃ HOÀN TẤT! Các biến sẵn sàng:\n",
      "   X_train_tfidf, X_test_tfidf, y_train, y_test\n",
      "   Vectorizer được lưu: tfidf_vectorizer.pkl\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T09:01:15.573559Z",
     "start_time": "2025-10-30T09:01:11.346364Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Assuming the previous code has been run and variables are available: X_train_tfidf, y_train\n",
    "\n",
    "# Create 3 models\n",
    "model_nb = MultinomialNB()\n",
    "model_logreg = LogisticRegression(max_iter=1000)  # Add max_iter to ensure convergence\n",
    "model_svm = LinearSVC()\n",
    "\n",
    "print(\"Đang huấn luyện Naive Bayes...\")\n",
    "model_nb.fit(X_train_tfidf, y_train)\n",
    "print(\"Xong!\")\n",
    "\n",
    "print(\"Đang huấn luyện Logistic Regression...\")\n",
    "model_logreg.fit(X_train_tfidf, y_train)\n",
    "print(\"Xong!\")\n",
    "\n",
    "print(\"Đang huấn luyện SVM (LinearSVC)...\")\n",
    "model_svm.fit(X_train_tfidf, y_train)\n",
    "print(\"Xong!\")\n",
    "\n",
    "# Optionally, save the models for later use\n",
    "import joblib\n",
    "joblib.dump(model_nb, 'model_nb.pkl')\n",
    "joblib.dump(model_logreg, 'model_logreg.pkl')\n",
    "joblib.dump(model_svm, 'model_svm.pkl')\n",
    "\n",
    "print(\"All models trained and saved!\")"
   ],
   "id": "2fdddba2d4f51f0b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang huấn luyện Naive Bayes...\n",
      "Xong!\n",
      "Đang huấn luyện Logistic Regression...\n",
      "Xong!\n",
      "Đang huấn luyện SVM (LinearSVC)...\n",
      "Xong!\n",
      "All models trained and saved!\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T09:08:24.281173Z",
     "start_time": "2025-10-30T09:08:23.921732Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "# Assuming the previous code has been run and variables are available: model_nb, model_logreg, model_svm, X_test_tfidf, y_test\n",
    "\n",
    "# Step 1: Make predictions\n",
    "y_pred_nb = model_nb.predict(X_test_tfidf)\n",
    "y_pred_logreg = model_logreg.predict(X_test_tfidf)\n",
    "y_pred_svm = model_svm.predict(X_test_tfidf)\n",
    "\n",
    "# Step 2: Evaluate each model\n",
    "\n",
    "# --- Evaluate Naive Bayes ---\n",
    "print(\"--- Kết quả của Naive Bayes ---\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_nb))\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "\n",
    "# --- Evaluate Logistic Regression ---\n",
    "print(\"\\n--- Kết quả của Logistic Regression ---\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_logreg))\n",
    "print(classification_report(y_test, y_pred_logreg))\n",
    "\n",
    "# --- Evaluate SVM (LinearSVC) ---\n",
    "print(\"\\n--- Kết quả của SVM (LinearSVC) ---\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "print(classification_report(y_test, y_pred_svm))"
   ],
   "id": "b5897ad560a827f3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Kết quả của Naive Bayes ---\n",
      "Accuracy: 0.6690426690426691\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Neg       0.68      0.60      0.64      9486\n",
      "         Neu       0.55      0.59      0.57      9817\n",
      "         Pos       0.78      0.80      0.79     11000\n",
      "\n",
      "    accuracy                           0.67     30303\n",
      "   macro avg       0.67      0.66      0.66     30303\n",
      "weighted avg       0.67      0.67      0.67     30303\n",
      "\n",
      "\n",
      "--- Kết quả của Logistic Regression ---\n",
      "Accuracy: 0.6872256872256872\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Neg       0.66      0.68      0.67      9486\n",
      "         Neu       0.58      0.56      0.57      9817\n",
      "         Pos       0.80      0.81      0.81     11000\n",
      "\n",
      "    accuracy                           0.69     30303\n",
      "   macro avg       0.68      0.68      0.68     30303\n",
      "weighted avg       0.69      0.69      0.69     30303\n",
      "\n",
      "\n",
      "--- Kết quả của SVM (LinearSVC) ---\n",
      "Accuracy: 0.6735306735306735\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Neg       0.64      0.66      0.65      9486\n",
      "         Neu       0.57      0.52      0.54      9817\n",
      "         Pos       0.78      0.82      0.80     11000\n",
      "\n",
      "    accuracy                           0.67     30303\n",
      "   macro avg       0.66      0.67      0.67     30303\n",
      "weighted avg       0.67      0.67      0.67     30303\n",
      "\n"
     ]
    }
   ],
   "execution_count": 25
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
